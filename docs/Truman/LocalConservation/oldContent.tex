% A cursory look at \eqnref{confusionBF} tells us which function spaces to look
% in for each variable:
% \[
% \begin{array}{lll}
% u\in L^2(\Omega_h) \quad& \hat u\in H^{1/2}(\Gamma_h) \quad& v\in H^1(\Omega_h)\\
% \bsigma\in \mathbf{L}^2(\Omega_h) \quad& \hat t\in H^{-1/2}(\Gamma_h) \quad&
% \btau\in \bs{H}(\bs{div},\Omega_h)\,.\\
% \end{array}
% \]

% All that is left to pin down this problem is a definition of our test norm so
% we can invert the Riesz operator and calculate our optimal test functions.
% Within each element, we perform a Bubnov-Galerkin solve for the optimal test
% functions. Define finite-dimensional subspaces
% $\mb{U}_h\subset\mb{U}:=L^2(\Omega_h)\times\mb{L}^2(\Omega_h)\times
% H^{1/2}(\Gamma_h)\times H^{-1/2}(\Gamma_h)$ the trial space and 
% $\mb{V}_h\subset\mb{V}:=H^1(\Omega_h)\times H(div,\Omega_h)$ the ``enriched''
% test space.
% For each $\mathbf{u}=\{u,\bsigma,\hat u,\hat t\}\in\mathbf{U}_h$, find
% $\mathbf{v}_{\mathbf{u}}=\{v_\mathbf{u},\btau_\mathbf{u}\}\in\mathbf{V_h}$ such that
% \[
% (\mathbf{v_u},\mathbf{w})_\mathbf{V}=b(\mathbf{u},\mathbf{w})\quad\forall\mathbf{w}\in\mathbf{V}
% \]
% As mentioned earlier the choice of test norm on $V$ can have profound
% influence on the robustness of our method. Unfortunately, the structure of the
% optimal test norm makes it non-localizable. For many problems, it suffices to
% use the so-call quasi-optimal test norm which is based on the adjoint of the
% $B$ operator, but for convection-diffusion type equations, the adjoint
% develops boundary layers which make solving for the optimal test functions
% much more difficult for small diffusion. In an earlier consideration of DPG
% for convection-diffusion problems, Chan \etal developed the more robust
% test norm\cite{ChanHeuerThanhDemkowicz2012}, 
% \begin{equation}
% \label{eq:robustNorm}
% \norm{(v,\btau)}^2_{\mathbf{V},\Omega_h}=
% \norm{\nabla\cdot\btau}^2+\norm{\min\left\{\frac{1}{\sqrt{\epsilon}},\frac{1}{\sqrt{|K|}}\right\}\btau}^2
% +\epsilon\norm{\nabla v}^2+\norm{\bbeta\cdot\nabla v}^2
% +\norm{\min\left\{\sqrt{\frac{\epsilon}{|K|}},1\right\}v^2}\,.
% \end{equation}
% Unfortunately, this test norm also has a few issues. For one, some of the
% assumptions that went into its development break down as the flow field
% degenerates to zero. In such cases the final $L^2$ term on $v$ can register
% higher error levels and trigger unnecessary refinements in smooth regions, see
% ref{}.
%TODO: have Jesse write about this

% \subsection{Locally Conservative Formulation}
% A simple control volume analysis will tell us that a locally conservative
% method must enforce that
% \begin{equation}
% \int_{\partial K}\hat t=\int_K f\,,\quad\forall K\in\Omega_h\,,
% \label{eq:localconservation}
% \end{equation}
% which is equivalent to having the set
% $\mathbf{v}_K:=\{v,\btau\}=\{1_K,\boldsymbol0\}$ for $K=1,\dots,N$ ($N$ is the
% number of mesh elements)
% in the test space, where each $1_K$ has value one on element $K$ and zero
% elsewhere.  In fact, if we insert this test function into
% \eqnref{confusionBF}, all of the $\tau$ and $\grad v$ terms vanish and we are
% left exactly with this condition.
% Numerical experiments imply that local conservation occurs in one dimension,
% but the standard DPG method is not exactly locally conservative for higher
% dimensional problems.
% 
% Following Moro \etal\cite{MoroNguyenPeraire11}, we can explicitly augment our
% test space with constants through the use of Lagrange multipliers. Going back
% to \eqnref{rieszapplied}, we can define our Lagrange function,
% \begin{equation}
% \label{eq:lagrangian}
% L(u_h,\blambda) = \frac{1}{2}\norm{R_V^{-1}(Bu_h-l)}_V^2
% -\sum_K\lambda_K\underbrace{\langle Bu_h-l,\mathbf{v}_K\rangle}_
% {\langle\hat t, 1_K\rangle_{\partial K}-\langle g,1_K\rangle_K}\,,
% \end{equation}
% where $\blambda=\{\lambda_1,\cdots,\lambda_N\}$.
% We then proceed as before and find the critical points of \eqnref{lagrangian},
% \begin{equation}
% \label{eq:modifiedBF}
% \frac{\partial L(u_h,\blambda)}{\partial u_h}=b(u_h,R_V^{-1}B\delta u_h)
% -l(R_V^{-1}B\delta u_h)
% -\sum_K\lambda_K b(\delta
% u_h,\mathbf{v}_K)=0\,,\quad\forall\delta u_h\in U_h
% \end{equation}
% \begin{equation}
% \label{eq:constraint}
% \frac{\partial
% L(u_h,\blambda)}{\partial\lambda_K}=-b(u_h,\mathbf{v}_K)+l(\mathbf{v}_K)=0\,,\quad\forall
% K\,.
% \end{equation}
% Equation \eqnref{modifiedBF} is just \eqnref{DPGmethod} with the extra
% Lagrange terms. As usual, the second equation just enforces the constraint. As
% a consequence, we now explicitly have constants in our test space and should
% enforce local conservation to machine precision. The negative side is that we
% have added an additional unknown associated with every mesh element and turned
% our well-behaved minimization into a saddle point problem.
% 
% This change has further consequences to how we compute our optimal test
% functions. Since constants are now explicitly represented in the test space,
% we only need to search for optimal test functions in the orthogonal complement
% of constants. The final term in \eqnref{robustNorm} is somewhat troublesome,
% but becomes unnecessary when solving in the orthogonal complement of
% constants. Instead, we can replace it with a much nicer zero mean term. Thus,
% \eqnref{robustNorm} becomes
% \begin{equation}
% \norm{(v,\btau)}^2_{\mathbf{V},\Omega_h}=
% \norm{\nabla\cdot\btau}^2+\norm{\min\left\{\frac{1}{\sqrt{\epsilon}},\frac{1}{\sqrt{|K|}}\right\}\btau}^2\\
% +\epsilon\norm{\nabla v}^2+\norm{\bbeta\cdot\nabla
% v}^2+\left(\int_Kv\right)^2\,.
% \end{equation}

