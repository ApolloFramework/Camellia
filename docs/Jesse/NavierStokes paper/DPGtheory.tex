\section{DPG as a minimum-residual method}
\seclab{optimalTest} 

%Petrov-Galerkin methods, in which the test space differs from the trial space, have been explored for over 30 years, beginning with the approximate symmetrization method of Barrett and Morton~\cite{BARRETT01101981}. The idea was continued with the SUPG method of Hughes, and the characteristic Petrov-Galerkin approach of Demkowicz and Oden~\cite{Demkowicz1986188}, which introduced the idea of tailoring the test space to change the norm in which a finite element method would converge.
%The idea of optimal test functions was introduced by Demkowicz and Gopalakrishnan in \cite{DPG2}.  Conceptually, these optimal test functions are the natural result of the minimization of a residual corresponding to the operator form of a variational equation. The connection between stabilization and least squares/minimum residual
%methods has been observed previously \cite{GLS}. However, the method in \cite{DPG2} distinguishes itself by measuring the residual of the natural \textit{operator form of the equation}, posed in the dual space and measured with the dual norm.  

Our starting point is the minimization of some measure of error over a finite-dimensional space, given an abstract variational formulation 
\begin{equation}
\eqnlab{variationEq}
\left\{
  \begin{array}{l}
    \text{Given } l \in V^*, \text{ find } u \in U  \text{ such that} \\ 
    b(u,v) = l(v), \quad \forall v\in V,
  \end{array}
  \right.
\end{equation}
where $b\LRp{\cdot,\cdot}: U \times V \to \mbb{R}$ is a continuous bilinear form.  Throughout the paper, we assume that the trial space $U$ and test space $V$ are real Hilbert spaces, and denote $U^*$ and $V^*$ as the respective topological dual spaces.  Throughout the paper, we suppose the variational problem \eqnref{variationEq} to be well-posed in the inf-sup sense. We can then identify a unique operator $B:U\rightarrow V^*$ such that 
\[
\langle Bu,v\rangle_{V^* \times V} \coloneqq b(u,v), \quad u\in U, v\in V
\]
with $\LRa{\cdot, \cdot}_{V^*\times V}$ denoting the duality pairing between $V^*$ and $V$, to obtain the operator form of the our variational problem
\begin{equation}
\eqnlab{dualEq}
Bu = l \quad \text{in } V^*.
\end{equation}
We are interested in minimizing the residual over the discrete approximating subspace $U_h \subset U$
\[
u_h = \underset{u_h\in U_h}{\arg\min}\, J(u_h) \coloneqq \frac{1}{2}\|l-Bu_h\|_{V^*}^2 \coloneqq\frac{1}{2} \sup_{v\in V\setminus\{0\}} \frac{| l(v)- b(u_h,v)|^2}{\nor{v}_V^2}.
\]
For convenience in writing, we will abuse the notation $\sup_{v \in V}$ to denote $\sup_{v\in V\setminus\{0\}}$ for the remainder of the paper.  If we define the problem-dependent \textit{energy norm} 
\[
\nor{u}_E \coloneqq \nor{Bu}_{V^*},
\]
then we can equate the minimization of $J(u_h)$ with the minimization of error in $\nor{\cdot}_E$. 

The first order optimality condition for minimization of the quadratic functional $J(u_h)$ requires the G\^ateaux derivative to be zero in all directions $\delta u \in U_h$,
\begin{align}
\left(l-Bu_h,B\delta u\right)_{V^*} = 0, \quad \forall \delta u \in U,
\label{orthog}
\end{align}
which is nothing more than the least-squares condition enforcing orthogonality of error with respect to the inner product on $V$.  

The difficulty in working with the first-order optimality condition~\eqref{orthog} is that the inner product $\LRp{\cdot,\cdot}_{V^*}$ cannot be evaluated explicitly.  However, we have that 
\begin{align}
\left(l-Bu_h,B\delta u\right)_{V^*} = \left(R_V^{-1}(l-Bu_h),R_V^{-1}B\delta u\right)_{V},
\label{rieszOrthog}
\end{align}
where $R_V: V\rightarrow V^*$ is the Riesz map mapping elements of a Hilbert space $V$ to elements of the dual $V^*$ defined by
\[
\LRa{R_Vv,\delta v}_{V^*\times V} \coloneqq \LRp{v,\delta v}_V.
\]
Furthermore, the Riesz operator is an isometry, such that $J(u_h) = \frac{1}{2}\nor{l-Bu_h}^2_{V^*} = \frac{1}{2}\nor{R_V^{-1}(l-Bu_h)}^2_{V}$.  Thus, satisfaction of~\eqref{rieszOrthog} is exactly equivalent to satisfaction of the original optimality conditions~\eqref{orthog}.  

\subsection{Optimal test functions}

%Throughout this dissertation, we assume that the trial space $U$ and test space $V$ are real Hilbert spaces, and denote $U'$ and $V'$ as the respective topological dual spaces. Let $U_h \subset U$ and $V_h\subset V$ be finite dimensional subsets. We are interested in the following problem  
%\begin{equation}
%\eqnlab{variationEq}
%\left\{
%  \begin{array}{l}
%    \text{Given } l \in V', \text{ find } u_h \in U_h  \text{ such that} \\ 
%    b(u_h,v_h) = l(v_h), \quad \forall v_h\in V_h,
%  \end{array}
%  \right.
%\end{equation}
%where $b\LRp{\cdot,\cdot}: U \times V \to \mbb{R}$ is a continuous
%bilinear form.  $U_h$ is chosen to be some trial space of approximating functions, but $V_h$ is as of yet unspecified. 
%
%Throughout the dissertation, we suppose the variational
%problem \eqnref{variationEq} to be well-posed. In that case, we can
%identify a unique operator $B:U\rightarrow V'$ such that
%\[
%\langle Bu,v\rangle_V \coloneqq b(u,v), \quad u\in U, v\in V
%\]
%with $\LRa{\cdot, \cdot}_V$ denoting the duality pairing between $V'$ and $V$, to obtain the operator form of the continuous variational problem
%\begin{equation}
%\eqnlab{dualEq}
%Bu = l \quad \text{in } V'.
%\end{equation}
%In other words, we can represent the continuous form of our variational equation
%\eqnref{variationEq} equivalently as the operator equation \eqnref{dualEq} with values in the
%dual space $V'$.  This motivates us to consider the conditions under which the solution to \eqnref{variationEq} is the solution to the minimum residual problem in $V'$ 
%\[
%u_h = \underset{u_h\in U_h}{\arg\min}\, J(u_h),
%\]
%where $J(w)$ is defined for $w\in U$ as 
%\[
%J(w) = \frac{1}{2}\|Bw-l\|_{V'}^2 \coloneqq\frac{1}{2} \sup_{v\in V\setminus\{0\}} \frac{| b(w,v)-l(v)|^2}{\nor{v}_V^2}.
%\]
%For convenience in writing, we will abuse the notation $\sup_{v \in V}$ to denote $\sup_{v\in V\setminus\{0\}}$ for the remainder of the dissertation.
%
%Let us define $R_V: V \to V'$ as the Riesz map, which identifies
%elements of $V$ with elements of $V'$ by 
%\[
%\langle R_V v,\delta
%v\rangle_V \coloneqq(v, \delta v)_V, \quad \forall \delta v \in V.
%\]
%Here, $(\cdot, \cdot)_V$ denotes the
%inner product in $V$. As $R_V$ and its inverse, $R_V^{-1}$, are both
%isometries, e.g.\ $\|f\|_{V'} = \|R_V^{-1} f\|_V, \forall f \in V'$, we
%have
%\begin{equation}
%\eqnlab{minimization}
%\min_{u_h\in U_h} J(u_h) = \frac{1}{2}\left\|Bu_h-l\right\|_{V'}^2 =  \frac{1}{2}\left\|R_V^{-1}(Bu_h-l)\right\|_V^2.
%\end{equation}
%The first order optimality condition for \eqnref{minimization} requires
%the G\^ateaux derivative to be zero in all directions $\delta u \in
%U_h$, i\.e\.,
%\begin{align*}
%\left(R_V^{-1}(Bu_h-l),R_V^{-1}B\delta u\right)_V = 0, \quad \forall \delta u \in U. 
%\end{align*}
We define, for a given trial function $\delta u \in U$, the corresponding {\em optimal test function} $v_{\delta u}$
\begin{equation}
\eqnlab{optv}
v_{\delta u} \coloneqq R_V^{-1}B\delta u \quad  \text{in } V.
\end{equation} 
By definition of the Riesz inverse, the optimality condition~(\ref{rieszOrthog}) becomes
\[
 \langle Bu_h-l, v_{\delta u}\rangle_V = 0, \quad \forall \delta u \in U
\]
which is exactly the standard variational equation in \eqnref{variationEq} with $v_{\delta u}$ as the test functions. By defining the optimal test space $V_{\rm opt} \coloneqq \{v_{\delta u} \text{ s.t. } \delta u\in U\}$, the solution of the discrete variational problem \eqnref{variationEq} with test space $V_h = V_{\rm opt}$ minimizes the residual in the dual norm $\nor{Bu_h-l}_{V'}$. 

%Since $U_h \subset U$ is spanned by a finite number of basis functions $\LRc{\varphi_i}_{i=1}^N$, \eqnref{optv} allows us to compute (for each basis function) a corresponding optimal test function $v_{\varphi_i}$. The collection $\LRc{v_{\varphi_i}}_{i = 1}^N$ of optimal test functions then forms a basis for the optimal test space.  In order to express optimal test functions defined in \eqnref{optv} in a more familiar form, we take  $\delta u = \varphi$, a generic basis function in $U_h$, and rewrite \eqnref{optv} as
%\[
%R_Vv_{\varphi} = B\varphi, \quad \text{in } V',
%\]
%which is, by definition, equivalent to
%\[
%\LRp{v_\varphi,\delta v}_V = \LRa{R_Vv_\varphi,\delta v}_{V}=
%\LRa{B\varphi, \delta v}_V = b\LRp{\varphi,\delta v}, \quad
%\forall \delta v \in V.
%\]
The inversion of the Riesz operator required to determine optimal test functions is done through the solution of the auxiliary variational problem
\begin{equation}
\eqnlab{optvVar}
\left(v_{\delta u},\delta v\right)_V = b({\delta u},\delta v), \quad \forall \delta v \in V.
\end{equation}
In general, for conforming finite element methods, test functions are continuous over the entire domain, and hence solving variational problem \eqnref{optvVar} for each optimal test function is a global operation over the entire mesh, rendering the method impractical. The development of discontinous Galerkin (DG) methods allows us to avoid this by adopting basis functions which are discontinuous over elements. In particular, the use of discontinuous test functions $\delta v$ and a \textit{localizable} norm $\nor{v}_{V(\Oh)}^2 = \sum_{K\in\Oh} \nor{v}_{V(K)}^2$, (where $\nor{v}_{V(K)}$ is a norm over the element $K$), reduces the problem of determining global optimal test functions in \eqnref{optvVar} to local problems that can be solved in an element-by-element fashion.

We note that solving \eqnref{optvVar} on each element exactly is still impossible since it amounts to inverting the infinite-dimensional Riesz map $R_V$. Instead, optimal test functions are approximated using the standard Bubnov-Galerkin method on an ``enriched" subspace $\tilde{V} \subset V$ such that $\dim(\tilde{V}) > \dim(U_h)$ elementwise \cite{DPG1, DPG2}. We assume in this paper that the approximation error in optimal test functions is negligible, and refer to \cite{practicalDPG} for estimating the effects of approximation error on DPG.

Finally, the DPG method boasts several attractive properties: 
\begin{itemize}
\item DPG provides a symmetric positive-definite stiffness matrix. Let $\{\phi_j\}_{j=1}^m$ be a basis for $U_h$, and $\{v_i\}_{i=1}^n$ a basis for $V_h$, such that $n>m$. Then, for $B_{ji} = b(\phi_j,v_i)$ and $l_i = \ell(v_i)$, DPG solves the ``internally preconditioned'' algebraic least squares system for degrees of freedom $u$
\begin{align*}
\LRp{B^T R_V^{-1}B} u  &= \LRp{B^T R_V^{-1}} l,
\end{align*}
where, under a localizable norm and discontinuous test functions, $R_V^{-1}$ is block diagonal.
\item DPG delivers the best approximation error in the ``energy norm" \cite{Bui-ThanhDemkowiczGhattas11a, DPG2, DPG4} 
\begin{equation}
\eqnlab{optimalError}
\nor{u-u_h}_{E} = \inf_{w\in U_h} \nor{u-w}_{E},
\end{equation}
where the energy norm $\nor{u}_{E}$ is defined 
\begin{equation}
\eqnlab{energyNorm} \nor{u}_{E} \coloneqq \nor{Bu}_{V'} = \sup_{v\in V}\frac{b(u,v)}{\nor{v}_V}.
\end{equation}
\item DPG inherits the natural property of minimum-residual methods that the energy error can be determined without knowing the exact solution --  $\|u-u_h\|_{U,E}  = \nor{Bu - Bu_h}_{V'} = \nor{R_V^{-1}\LRp{l-Bu_h}}_{V}$ shows that the energy error is simply the residual measured in a specific norm.  The energy error for DPG can be determined by computing the \textit{error representation function} $e \coloneqq R_V^{-1}\LRp{l-Bu_h}$ through
\[
\left(e,\delta v\right)_V = b(u-u_h,\delta v) = l\LRp{\delta v} - b(u_h,\delta v)
\]
and measuring $\|e\|_V$.  %This is simply a consequence of the least-squares nature of DPG; the energy error is simply the norm of the residual in $V'$.  
We can compute the squared norm over the domain $\nor{e}_{V(\Oh)}^2$ as the sum of element contributions $\sum_{K\in \Oh} \nor{e}_{V(K)}^2$, and we define $e_K^2 \coloneqq \nor{e}_{V(K)}^2$ as a local error indicator with which we can drive adaptive mesh refinement.  
\end{itemize}

\subsection{The ultra-weak variational formulation}
\seclab{abstractUweak}

We note that the above theory holds for any variational formulation that allows for discontinuous test functions.  Though alternative discretizations have been successful \cite{primalDPG}, we focus primarily on the ultra-weak variational formulation.  

The ultra-weak variational formulation begins with a first order system $Au = f$.  After multiplying by a test function $v$, we integrate all equations by parts, such that over one element, we have
\[
\LRp{Au,v}_{L^2(K)} = \LRp{u,A_h^*v}_{L^2(K)} + \LRa{\uh,v}_{\partial K}.
\]
$A_h^*v$ is the broken formal adjoint, which corresponds to the adjoint operator acting element-wise on $v$.  In traditional DG methods, the numerical flux $\uh$ is constructed as some function of solution values on elements adjacent to $\partial K$.  Under the ultra-weak formulation, these numerical fluxes are identified as additional unknowns, akin to hybridized discontinuous Galerkin (HDG) methods \cite{hybridDG}.\footnote{While the boundary term resulting from integration by parts of a gradient (the numerical trace), is typically identified as an additional unknown, the boundary term resulting from integration by parts of a divergence (the numerical flux) is not, and is approximated using a DG flux.  The ultra-weak variational formulation identifies both as independent unknowns.} 

We define the mesh $\Oh$ as the partitioning of $\Omega$ into non-overlapping elements $K_j, j = 1,\hdots,\Nel$ through $\Oh = \cup_{j=1}^\Nel K_j$.  We define also the mesh ``skeleton" by $\Gh = \cup_{j=1}^\Nel \partial K_j$; the set of all element faces/edges. The ultra weak formulation is given as the sum of the independent element contributions in the mesh $\Oh$, which, under proper regularity assumptions, yields the bilinear form $b\LRp{\LRp{u,\uh},v}$ 
\[
b\LRp{\LRp{u,\uh},v} = \sum_{K\in \Oh} \LRp{u,A_h^*v}_{L^2(K)} + \LRa{\uh,v}_{\partial K} = \LRp{u,A^*_h v}_{\L} + \LRa{\uh,\jump{v}}_{\Gh},
\]
where $\jump{v}$ is the jump of $v$ across all edges that make up the skeleton $\Gh$.  We refer to \cite{analysisDPG, Bui-ThanhDemkowiczGhattas11b, stokesDPG} for a detailed discussion of the proper energy setting and spaces for each variable, as well as detailed analysis of well-posedness of the ultra-weak variational formulation for a large range of problems.  

%The \cite{globalLocalDPG} for mortar/global test space connections.  

%The naming of the discontinuous Petrov-Galerkin method refers to the fact that the method is a Petrov-Galerkin method, and that the test functions are specified to be discontinuous across element boundaries. There is no specification of the regularity of the trial space, and we stress that the idea of DPG is not inherently tied to a single variational formulation \cite{Bui-ThanhDemkowiczGhattas11a}. Additionally, Cohen, Dahmen and Welper simultaneously extended the minimum residual concept behind DPG to general variational settings and avoid the use of discontinuous test functions by formulating the minimum residual method as a saddle-point problem \cite{DahmenVariationalStabilization}.  
%
%In most of the DPG literature, however, the discontinuous Petrov-Galerkin method refers to the combination of the concept of locally computable optimal test functions introduced in Section \secref{optimalTest} with the so-called ``ultra-weak formulation" \cite{DPG1,DPG2,DPG3,DPG4,DPGElas,DBLP:journals/procedia/NiemiCC11}. Unlike the previous two sections in which we studied the general equation \eqnref{variationEq} given by abstract bilinear and linear forms, we now consider a concrete instance of \eqnref{variationEq} resulting from an ultra-weak formulation for an abstract first-order system of PDEs $Au = f$. Additionally, from this section onwards, we will refer to DPG as the pairing of the ultra-weak variational formulation with the concept of locally computable optimal test functions. 
%
%We begin by partitioning the domain of interest $\Omega$ into $\Nel$ non-overlapping elements $K_j, j = 1,\hdots,\Nel$ such that $\Oh = \cup_{j=1}^\Nel K_j$ and $\overline{\Omega} = \overline{\Omega}_h$. Here, $h$ is defined as $h= \max_{j\in \LRc{1,\hdots,\Nel}}\text{diam}\LRp{K_j}$.  We denote the mesh ``skeleton" by $\Gh = \cup_{j=1}^\Nel \partial K_j$; the set of all faces/edges $e$, each of which come with a normal vector ${n}_e$. The internal skeleton is then defined as $\Gamma^0_h = \Gh \setminus \partial \Omega$. If a face/edge $e \in \Gh$ is the intersection of $\partial K_i$ and $\partial K_j$, $i \ne j$, we define the following jumps:
%\[
%\jump{v} = \text{sgn} \LRp{{n}^-}v^- + \text{sgn} \LRp{{n}^+}v^+, \quad
%\jump{\tau \cdot n} = {n}^-\cdot \tau^- + {n}^+\cdot\tau^+,
%\]
%where
%\[
%\text{sgn}\LRp{{n}^{\pm}} =
%\left\{
%\begin{array}{ll}
%1 & \text{if } {n}^{\pm} = {n}_e \\
%-1 & \text{if } {n}^\pm = -{n}_e
%\end{array}
%\right..
%\]
%For $e$ belonging to the domain boundary $\partial \Omega$, we define
%\[
%\jump{v} = v, \quad
%\jump{\tau \cdot n} = {n}_e\cdot \tau.
%\]
%Note that we allow arbitrariness in assigning ``-'' and ``+'' quantities to the adjacent elements $K_i$ and $K_j$.
%%For the rest of the paper, we will use the same notation for both a function and its trace (if it is well-defined) when there is no ambiguity.
%
%The ultra-weak formulation for $Au = f$ on $\Oh$, ignoring boundary
%conditions for now, reads
%\begin{equation}
%\eqnlab{uweak}
%b\left(\left(u, \widehat{u}\right),v\right) \coloneqq \langle \widehat{u}, \jump{v}
%\rangle_{\Gh} - (u,A_h^*v)_{\Oh}= \LRp{f,v}_{\Oh},
%\end{equation}
%where we have denoted $\LRa{\cdot,\cdot}_{\Gh}$ as the duality
%pairing on $\Gh$, $\LRp{\cdot,\cdot}_{\Oh}$ the $L^2$-inner
%product over $\Oh$, and $A_h^*$ the formal adjoint resulting from
%element-wise integration by parts.  Occasionally, for simplicity in
%writing, we will ignore the subscripts in the duality pairing and
%$L^2$-inner product if they are $\Gh$ and $\Oh$. Both the
%inner product and formal adjoint are understood to be taken
%element-wise. Using the ultra-weak formulation, the regularity
%requirement on solution variable $u$ is relaxed, that is, $u$ is now
%square integrable for the ultra-weak formulation \eqnref{uweak} to be
%meaningful, instead of being (weakly) differentiable.  The trade-off
%is that $u$ does not admit a trace on $\Gh$ even though it did
%originally. Consequently, we need to introduce an additional new
%``trace'' variable $\widehat{u}$ in \eqnref{uweak}, that is defined only on
%$\Gh$.
%
%The energy setting is now clear; namely,
%\[
%u\in L^2\LRp{\Oh} \equiv L^2(\Omega), \quad v\in V=D(A^*_h), \quad
%\widehat{u}\in \gamma(D(A)),
%\]
%where $D(A_h^*)$ denotes the broken graph space corresponding to $A_h^*$,
%and $\gamma(D(A))$ the trace space (assumed to exist) of the graph space of
%operator $A$. The first discussion of the well-posedness of DPG with the ultra-weak formulation can be found in \cite{analysisDPG}, where the proof is presented for the Poisson and convection-diffusion equations. A more comprehensive discussion of the abstract setting for DPG with the ultra-weak formulation using the graph space, as well as a more general proof of well-posedness, can be consulted in \cite{Bui-ThanhDemkowiczGhattas11b}. 

